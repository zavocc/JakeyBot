from core.ai.assistants import Assistants
import core.aimodels._template_ # For type hinting
import discord
import importlib
import io

class BaseChat():
    def __init__(self, bot):
        self.bot: discord.Bot = bot

    ###############################################
    # Ask slash command
    ###############################################
    async def ask(self, ctx: discord.ApplicationContext, prompt):
        await ctx.response.defer(ephemeral=True)

        _infer: core.aimodels._template_.Completions = importlib.import_module(f"core.aimodels.gemini").Completions(
            discord_ctx=ctx,
            discord_bot=self.bot,
            model_name="gemini-1.5-flash-002")
       
         ###############################################
        # Answer generation
        ###############################################
        _system_prompt = await Assistants.set_assistant_type("jakey_system_prompt", type=0)
        _result = await _infer.completion(prompt=prompt, system_instruction=_system_prompt)

        _system_embed = discord.Embed(
            # Truncate the title to (max 256 characters) if it exceeds beyond that since discord wouldn't allow it
            title=prompt.replace("\n", " ")[0:20] + "...",
            description=str(_result),
            color=discord.Color.random()
        )
    
        _system_embed.set_footer(text="Responses generated by AI may not give accurate results! Double check with facts!\nTo experience the full feature with memory, ask me in your server or in DMs by @mentioning me")

        # Embed the response if the response is more than 2000 characters
        # Check to see if this message is more than 2000 characters which embeds will be used for displaying the message
        if len(_result) > 4096:
            # Send the response as file
            await ctx.respond("⚠️ Response is too long. But, I saved your response into a markdown file", file=discord.File(io.StringIO(_result), "response.md"))
        else:
            await ctx.respond(embed=_system_embed)